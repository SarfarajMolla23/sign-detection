# Gesture Detection

This project utilizes the **SSD MobileNet V2 COCO** model for real-time object detection, specifically for gesture recognition. The model is trained on the **COCO** (Common Objects in Context) dataset, enabling the detection of various objects in images and video streams.

## Technologies Used:
- **Python 3.10**
- **OpenCV**
- **TensorFlow 2.10.0**

## Steps to Run:

1. **Clone this Repository**  
   Clone the repository to your local machine using:
   ```bash
   git clone https://github.com/your-username/repository-name.git
   ```

2. **Create a Virtual Environment**  
   Create a virtual environment to manage dependencies:
   ```bash
   python3 -m venv /path/to/new/virtual/environment
   ```

3. **Activate the Virtual Environment**  
   Activate the virtual environment:
   - On Windows:
     ```bash
     .\venv\Scripts\activate
     ```
   - On macOS/Linux:
     ```bash
     source venv/bin/activate
     ```

4. **Install Required Dependencies**  
   Install the necessary Python packages:
   ```bash
   pip install -r requirements.txt
   ```

5. **Run the Jupyter Notebook**  
   Open the project folder in Jupyter Notebook, and run all the cells to start the gesture detection process.

---

Make sure you add a `requirements.txt` file in your repository to list the dependencies, for example:

```txt
tensorflow==2.10.0
opencv-python
```

Demo Images:
![Screenshot 2024-12-03 135446](https://github.com/user-attachments/assets/5573ad2e-1e82-4116-9aa1-4fb6e533b71c)
![Screenshot 2024-12-03 133544](https://github.com/user-attachments/assets/f7cbb97f-7270-42f3-a1a8-f1b1537af98e)
![Screenshot 2024-12-03 133404](https://github.com/user-attachments/assets/7a128b14-d9bb-40b7-b02b-85317cc0096b)

